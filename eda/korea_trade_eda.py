import os
import warnings
import pandas as pd
from sqlalchemy import create_engine
from dotenv import load_dotenv
import json
import google.generativeai as genai

# Configuration
warnings.filterwarnings('ignore')
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = 'gemini-1.5-flash'
genai.configure(api_key=GEMINI_API_KEY)
MODEL = genai.GenerativeModel(GEMINI_MODEL_NAME)

EDA_DIR = os.getenv("EDA_DIR")
eda_path = os.path.join(EDA_DIR, "outputs", "korea_trade")

# DB connection
PG_USER = os.getenv("POSTGRES_USER")
PG_PASSWORD = os.getenv("POSTGRES_PASSWORD")
PG_DB = os.getenv("POSTGRES_DB")
PG_HOST = os.getenv("POSTGRES_HOST")
PG_PORT = os.getenv("POSTGRES_PORT")

engine = create_engine(f"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}")

# Helper functions for safe data extraction
def safe_get_value(df, index, column, default="N/A"):
    """Safely extract value from DataFrame with bounds checking"""
    try:
        if len(df) > index and column in df.columns:
            value = df.iloc[index][column]
            if pd.isna(value):
                return default
            return value
        return default
    except (IndexError, KeyError):
        return default

def safe_convert_numeric(value, default=0):
    """Safely convert value to numeric, return default if conversion fails"""
    try:
        if pd.isna(value) or value == "N/A":
            return default
        return float(value)
    except (ValueError, TypeError):
        return default

# Korea Export Trade
def load_korea_export_trade_data(engine):
    query = """
    SELECT date, country, partner, indicator, export_amount, trade_yoy, trade_share
    FROM trade_korea_export_country_variation_processed
    ORDER BY date DESC, trade_share DESC, export_amount DESC;
    """
    return pd.read_sql(query, engine)

# Korea Import Trade
def load_korea_import_trade_data(engine):
    query = """
    SELECT date, country, partner, indicator, import_amount, trade_yoy, trade_share
    FROM trade_korea_import_country_variation_processed
    ORDER BY date DESC, trade_share DESC, import_amount DESC;
    """
    return pd.read_sql(query, engine)

# mode must be 'export' or 'import'
def analyse_trade(df, mode='export'):
    assert mode in ['export', 'import']
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')

    amount_col = 'export_amount' if mode == 'export' else 'import_amount'

    # Latest month
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]

    # Exclude World
    df_latest_filtered = df_latest[df_latest['partner'] != 'World']
    top_partners = (
        df_latest_filtered.groupby(['country', 'partner'], as_index=False)
        .agg({amount_col: 'sum', 'trade_share': 'sum'})
        .sort_values(amount_col, ascending=False)
        .head(5)
    )

    # Partner share trends (filter by significant trade share)
    avg_share_by_partner = df.groupby('partner')['trade_share'].mean()
    significant_partners = avg_share_by_partner[avg_share_by_partner >= 0.1].index
    df_significant = df[df['partner'].isin(significant_partners)]

    share_trends = (
        df_significant.groupby(['date', 'country', 'partner'], as_index=False)
        .agg({'trade_share': 'sum'})
        .sort_values(['country', 'partner', 'date'])
    )

    # Summary statistics
    summary_stats = df[[amount_col, 'trade_yoy']].describe().round(2)

    # Trend analysis for top 3
    top3 = top_partners.head(3)[['country', 'partner']]
    df_filtered = df[df['partner'] != 'World']
    mask = df_filtered.set_index(['country', 'partner']).index.isin(top3.set_index(['country', 'partner']).index)
    top3_trend = df_filtered[mask][['date', 'country', 'partner', amount_col, 'trade_share']].sort_values(['country', 'partner', 'date'])

    return {
        'mode': mode,
        'top_partners': top_partners,
        'share_trends': share_trends,
        'summary_stats': summary_stats,
        'top3_trend': top3_trend
    }

# Map English Commodity Names
translation_map = {
# Electronics
"Î©îÎ™®Î¶¨": "Memory chips",
"ÌîÑÎ°úÏÑ∏ÏÑúÏôÄ Ïª®Ìä∏Î°§Îü¨[Î©îÎ™®Î¶¨„ÜçÎ≥ÄÌôòÍ∏∞„ÜçÎÖºÎ¶¨ÌöåÎ°ú„ÜçÏ¶ùÌè≠Í∏∞„ÜçÌÅ¥Î°ù(clock)„ÜçÌÉÄÏù¥Î∞ç(timing) ÌöåÎ°úÎÇò Í∑∏ Î∞ñÏùò ÌöåÎ°úÎ•º Í∞ñÏ∂ò Í≤ÉÏù∏ÏßÄÎäî ÏÉÅÍ¥ÄÏóÜÎã§]": "Processors and controllers",
"ÏÜîÎ¶¨Îìú Ïä§ÌÖåÏù¥Ìä∏(solid-state)Ïùò ÎπÑÌúòÎ∞úÏÑ± Í∏∞ÏñµÏû•Ïπò": "SSD storage",
"Ïù∏ÏáÑÌöåÎ°ú": "Printed circuits",
"Î∞òÎèÑÏ≤¥ÎîîÎ∞îÏù¥Ïä§ÎÇò Ï†ÑÏûêÏßëÏ†ÅÌöåÎ°ú Ï†úÏ°∞Ïö© Í∏∞Í≥ÑÏôÄ Í∏∞Í∏∞": "Semiconductor manufacturing equipment",
"Ïú†Í∏∞Î∞úÍ¥ëÎã§Ïù¥Ïò§Îìú(Ïò§ÏóòÏù¥Îîî)Ïùò Í≤É": "OLED displays",
# Vehicles
"Ïã§Î¶∞ÎçîÏö©ÎüâÏù¥ 1,500ÏãúÏãú Ï¥àÍ≥º 3,000ÏãúÏãú Ïù¥ÌïòÏù∏ Í≤É": "Vehicles (1.5-3L engine)",
"Í∑∏ Î∞ñÏùò Ï∞®Îüâ(Î∂àÍΩÉÏ†êÌôîÏãù ÌîºÏä§ÌÜ§ ÎÇ¥Ïó∞Í∏∞Í¥ÄÍ≥º Ï∂îÏßÑÏö© Î™®ÌÑ∞Î°úÏÑúÏùò Ï†ÑÎèôÍ∏∞Î•º Îëò Îã§ Í∞ñÏ∂ò Í≤ÉÏúºÎ°úÏÑú, Ïô∏Î∂Ä Ï†ÑÏõêÏóê ÌîåÎü¨Í∑∏Î•º ÍΩÇÏïÑ Ï∂©Ï†ÑÌï† Ïàò ÏûàÎäî Î∞©ÏãùÏùò Í≤ÉÏùÄ Ï†úÏô∏ÌïúÎã§)": "Hybrid vehicles (non-plug-in)",
"ÏäπÏö©ÏûêÎèôÏ∞®Ïö©[Ïä§ÌÖåÏù¥ÏÖòÏôúÍ±¥(station wagon)Í≥º Í≤ΩÏ£º ÏûêÎèôÏ∞®Ïö©ÏùÑ Ìè¨Ìï®ÌïúÎã§]": "Passenger vehicles",
"Í∏∞Ïñ¥Î∞ïÏä§ÏôÄ Í∑∏ Î∂ÄÎ∂ÑÌíà": "Transmission parts",
"Í∑∏ Î∞ñÏùò ÌôîÎ¨ºÏÑ†Í≥º ÌôîÍ∞ùÏÑ†": "Other Cargo & Passenger Ships",
# Machinery
"Ï†ú8471Ìò∏Ïóê Ìï¥ÎãπÌïòÎäî Í∏∞Í≥ÑÏùò Î∂ÄÎ∂ÑÌíàÍ≥º Î∂ÄÏÜçÌíà": "Machinery parts (HS8471)",
"360ÎèÑ ÌöåÏ†ÑÏùò ÏÉÅÎ∂ÄÍµ¨Ï°∞Î•º Í∞ÄÏßÑ Í∏∞Í≥Ñ": "Rotating machinery",
"ÌååÏáÑÍ∏∞ÎÇò Î∂ÑÏáÑÍ∏∞": "Crushers/grinders",
"ÏûêÏ≤¥ Ï§ëÎüâÏù¥ 2,000ÌÇ¨Î°úÍ∑∏Îû®ÏùÑ Ï¥àÍ≥ºÌïòÎäî Í≤É": "Heavy equipment (>2T)",
"ÌÉ±Ïª§(tanker)": "Tankers",
# Chemicals
"ÌååÎùº-ÌÅ¨Ïã§Î†å": "Para-xylene",
"Ïò§Î•¥ÌÜ†Ïù∏ÏÇ∞ÏàòÏÜå Ïù¥ÏïîÎ™®ÎäÑ(Ïù∏ÏÇ∞Ïù¥ÏïîÎ™®ÎäÑ)": "Ammonium phosphate",
"Ìô©ÏÇ∞ÏïîÎ™®ÎäÑ": "Ammonium sulfate",
"ÏÇ∞ÌôîÎãàÏºàÍ≥º ÏàòÏÇ∞ÌôîÎãàÏºà": "Nickel compounds",
"Í≤ΩÏßàÏú†(ËºïË≥™Ê≤π)ÏôÄ Ï°∞Ï†úÌíà": "Light oils",
"Î∞ïÌïòÏú†[Î©òÌÉÄ ÌîºÌéòÎ¶¨ÌÉÄ(Mentha piperita)]": "Peppermint oil",
"Î©îÌã∏ÎîîÏóêÌÉÑÏò¨ÏïÑÎØºÍ≥º ÏóêÌã∏ÎîîÏóêÌÉÑÏò¨ÏïÑÎØº": "Methyldiethanolamine & Ethyldiethanolamine",
# Energy & Raw Materials
"Ïú†Ïó∞ÌÉÑ": "Bituminous coal",
"ÏÑùÏú†ÏôÄ Ïó≠Ï≤≠Ïú†(ÁÄùÈùëÊ≤π)(ÏõêÏú†Î°ú ÌïúÏ†ïÌïúÎã§)": "Crude petroleum oil",
"Íµ¨Î¶¨Í¥ëÍ≥º Í∑∏ Ï†ïÍ¥ë(Á≤æÈëõ)": "Copper ores and concentrates",
"ÏùëÍ≤∞ÏãúÌÇ§ÏßÄ ÏïäÏùÄ Í≤É": "Uncondensed materials",
"Ïö∞ÎùºÎäÑ 235Î•º ÎÜçÏ∂ïÌïú Ïö∞ÎùºÎäÑÍ≥º Í∑∏ ÌôîÌï©Î¨º, ÌîåÎ£®ÌÜ†ÎäÑÍ≥º Í∑∏ ÌôîÌï©Î¨º, Ìï©Í∏à„ÜçÎ∂ÑÏÇ∞Î¨º(ÂàÜÊï£Áâ©)[ÏÑúÎ©ß(cermet)ÏùÑ Ìè¨Ìï®ÌïúÎã§]„ÜçÎèÑÏûêÏ†úÌíàÍ≥º Ïù¥Îì§Ïùò ÌòºÌï©Î¨º(Ïö∞ÎùºÎäÑ 235Î•º ÎÜçÏ∂ïÌïú Ïö∞ÎùºÎäÑ„ÜçÌîåÎ£®ÌÜ†ÎäÑÏù¥ÎÇò Ïù¥Îì§Ïùò ÌôîÌï©Î¨ºÏùÑ Ìï®Ïú†ÌïòÎäî Í≤ÉÏúºÎ°ú ÌïúÏ†ïÌïúÎã§)": "Enriched uranium and plutonium compounds",
"ÏïÑÎØ∏ÎÖ∏Î†âÏä§(INN)„ÜçÎ∏åÎ°úÌã∞Ï°∏Îûå(INN)„ÜçÌÅ¥Î°úÌã∞ÏïÑÏ†úÌåú(INN)„ÜçÌÅ¥Î°ùÏÇ¨Ï°∏Îûå(INN)„ÜçÎç±Ïä§Ìä∏Î°úÎ™®ÎùºÎßàÏù¥Îìú(INN)„ÜçÌï†Î°ùÏÇ¨Ï°∏Îûå(INN)„ÜçÏºÄÌÉÄÏ°∏Îûå(INN)„ÜçÎ©îÏÜåÏπ¥Î∏å(INN)„ÜçÏò•ÏÇ¨Ï°∏Îûå(INN)„ÜçÌéòÎ™∞Î¶∞(INN)„ÜçÌéúÎîîÎ©îÌä∏ÎùºÏßÑ(INN)„ÜçÌéúÎ©îÌä∏ÎùºÏßÑ(INN)„ÜçÏÑúÌéúÌÉÄÎãê(INN)Í≥º Ïù¥Îì§Ïùò Ïóº": "Pharmaceutical compounds",
"ÌÉÑÌôîÏπºÏäò": "Calcium carbide",
"Ï°∞Ïú†(Á≤óÊ≤π)": "Crude petroleum oil",
# Other
"ÌÅ¨ÎûúÎ≤†Î¶¨(cranberry)„ÜçÎπåÎ≤†Î¶¨(bilberry)ÏôÄ Í∑∏ Î∞ñÏùò Î∞ïÏãúÎãàÏóÑ(Vaccinium)ÏÜçÏùò Í≥ºÏã§": "Cranberries and bilberries",
"ÎØ∏ÏÉùÎ¨ºÏÑ± ÏßÄÎ∞©Í≥º Í∏∞Î¶Ñ Î∞è Ïù¥Îì§Ïùò Î∂ÑÌöçÎ¨º": "Microbial fats and oils",
"Î¶¨Ìä¨Ïù¥Ïò® Ï∂ïÏ†ÑÏßÄ": "Lithium batteries",
"Ïä§ÎßàÌä∏Ìè∞": "Smartphones",
"ÌÖåÏù¥Î∏îÎ¶∞ÎÑ®(table linen)(Î©îÎ¶¨ÏïºÏä§ Ìé∏Î¨ºÏù¥ÎÇò Îú®Í∞úÏßà Ìé∏Î¨ºÎ°ú ÌïúÏ†ïÌïúÎã§)": "Table linen",
"Ï£ºÎ°ú Ïû¨ÏÉù„ÜçÎ∞ò(Âçä)Ìï©ÏÑ± Ïä§ÌÖåÏù¥ÌîåÏÑ¨Ïú†ÏôÄ ÌòºÎ∞©Ìïú Í≤É": "Recycled fiber blends",
"ÌÖåÌä∏ÎùºÏÇ¨Ïù¥ÌÅ¥Î¶∞Í≥º Ïù¥Îì§Ïùò Ïú†ÎèÑÏ≤¥, Ïù¥Îì§Ïùò Ïóº": "Tetracycline & Derivatives",
"Í≥°Î¨ºÏùò Ïî®Îàà[ÏõêÎûò Î™®ÏñëÏù∏ Í≤É„ÜçÏïïÏ∞©Ìïú Í≤É„ÜçÌîåÎ†àÏù¥ÌÅ¨(flake) Î™®ÏñëÏù∏ Í≤É„ÜçÏûòÍ≤å Î∂ÄÏàú Í≤ÉÏúºÎ°ú ÌïúÏ†ïÌïúÎã§]": "Cereal Germs",
"Ïñ¥Î•òÏùò ÏßÄÎ∞©Í≥º Í∏∞Î¶Ñ Î∞è Í∑∏ Î∂ÑÌöçÎ¨º[Í∞ÑÏú†(ËÇùÊ≤π)Îäî Ï†úÏô∏ÌïúÎã§]": "Fish Fats & Oils",
"Ï†úÎèÑÌåêÏùÑ Í∞ñÏ∂ò Ï†úÎèÑÍ∏∞(ÏûêÎèôÏãùÏù∏ÏßÄÏóê ÏÉÅÍ¥ÄÏóÜÎã§)": "Drawing Boards & Instruments",
"Í∏∞ÌÉÄ": "Others",
}

# Korea Increased Export Trade Items
def load_korea_export_increase_items_data(engine):
    query = """
    SELECT *
    FROM trade_korea_export_increase_items_processed
    WHERE commodity_name IS NOT NULL 
    AND export_amount > 0
    ORDER BY date DESC, export_amount DESC;
    """
    return pd.read_sql(query, engine)

# Korea Increased Import Trade Items
def load_korea_import_increase_items_data(engine):
    query = """
    SELECT *
    FROM trade_korea_import_increase_items_processed
    WHERE commodity_name IS NOT NULL 
    AND import_amount > 0
    ORDER BY date DESC, import_amount DESC;
    """
    return pd.read_sql(query, engine)

# Analyse Increase Export and Import Items
def analyse_increase_items(df, mode='export'):
    assert mode in ['export', 'import']

    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['trade_yoy'] = pd.to_numeric(df['trade_yoy'], errors='coerce')

    value_col = 'export_amount' if mode == 'export' else 'import_amount'
    df[value_col] = pd.to_numeric(df[value_col], errors='coerce')

    df['commodity_name_en'] = df['commodity_name'].map(translation_map)

    # Rename duplicate 'Others'
    count = 1
    for idx in df[df['commodity_name_en'] == 'Others'].index:
        df.loc[idx, 'commodity_name_en'] = f'Others Type: {count}'
        count += 1

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]

    print(f"[{mode.upper()}] Analysis for latest date: {latest_date}")
    print(f"Total records in latest month: {len(df_latest)}")

    # Top YoY growth commodities
    top_yoy_growth = (
        df_latest[df_latest['trade_yoy'].notna()]
        .groupby(['commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean',
        })
        .sort_values('trade_yoy', ascending=False)
        .head(10)
    )

    # Top by total amount
    top_amount = (
        df_latest.groupby(['commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean',
        })
        .sort_values(value_col, ascending=False)
        .head(10)
    )

    # Monthly trend
    top5 = top_amount['commodity_name_en'].head(5).tolist()
    monthly_trend = (
        df[df['commodity_name_en'].isin(top5)]
        .groupby(['date', 'commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean'
        })
        .sort_values(['commodity_name_en', 'date'])
    )

    # YoY stats
    yoy_stats = df_latest[df_latest['trade_yoy'].notna()]['trade_yoy'].describe()

    # Partner analysis
    partner_analysis = (
        df_latest[df_latest['commodity_name_en'].isin(top5)]
        .groupby(['commodity_name_en', 'partner'], as_index=False)
        .agg({value_col: 'sum'})
        .sort_values(['commodity_name_en', value_col], ascending=[True, False])
    )

    return {
        'mode': mode,
        'latest_date': latest_date,
        'total_records': len(df_latest),
        'top_yoy_growth': top_yoy_growth,
        'top_amount': top_amount,
        'monthly_trend': monthly_trend,
        'yoy_statistics': yoy_stats,
        'partner_analysis': partner_analysis
    }

# Export and Import Main Items Value Analysis
def load_korea_export_import_main_items_data(engine):
    query = """
    SELECT date, country, category as trade_type, indicator as item, value, yoy_change
    FROM trade_korea_trade_items_yoy_processed
    ORDER BY date, trade_type, item;
    """
    return pd.read_sql(query, engine)

def analyse_export_import_value_index(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df['yoy_change'] = pd.to_numeric(df['yoy_change'], errors='coerce')

    # Translation
    translation_map = {
        "Ï†ÑÏßÄ": "Battery",
        "Î≥ÄÏïïÍ∏∞": "Transformer",
        "Ï†úÌä∏Ïú†": "Jet fuel",
        "ÌúòÎ∞úÏú†": "Gasoline",
        "Í∏∞Ï¥àÎ¨¥Í∏∞ÌôîÌï©Î¨º": "Basic chemical",
        "Ï≤úÏó∞Í∞ÄÏä§(LNG)": "Natural gas (LNG)",
        "Ïú§ÌôúÏú†Î∞èÍ∑∏Î¶¨Ïä§": "Lubricants and greases",
        "Ï§ëÌõÑÌåê(ÎëêÍªò3mmÏù¥ÏÉÅ)": "Thick plate (3mm or more)",
    }
    df['item_en'] = df['item'].map(translation_map).fillna(df['item'])

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date].dropna(subset=['yoy_change'])

    # Top ‚Üë and Bottom ‚Üì YoY Changes
    top_yoy = df_latest.sort_values('yoy_change', ascending=False).head(5)
    bottom_yoy = df_latest.sort_values('yoy_change', ascending=True).head(5)

    # Volatility: standard deviation of value index
    volatility = (
        df.groupby(['item_en', 'trade_type'])['value']
        .std()
        .sort_values(ascending=False)
    )

    # Trend pivot tables (for external plotting)
    pivot_yoy = df.pivot_table(index='date', columns=['item_en', 'trade_type'], values='yoy_change')
    pivot_value = df.pivot_table(index='date', columns=['item_en', 'trade_type'], values='value')

    return {
        'latest_date': latest_date,
        'top_yoy': top_yoy,
        'bottom_yoy': bottom_yoy,
        'volatility': volatility,
        'pivot_yoy': pivot_yoy,
        'pivot_value': pivot_value,
    }

# Load Korea Trade Data
def load_korea_trade_data(engine):
    query = """
    SELECT date, country, partner, category AS trade_type, value, yoy_change
    FROM trade_korea_trade_yoy_processed
    ORDER BY date, trade_type, partner;
    """
    return pd.read_sql(query, engine)

# Analyze Trade YoY Data
def analyse_trade_yoy(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df['yoy_change'] = pd.to_numeric(df['yoy_change'], errors='coerce')

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]
    exports = df_latest[df_latest['trade_type'] == 'Total Exports']
    imports = df_latest[df_latest['trade_type'] == 'Total Imports']

    # Filter out 'World' from partner calculations
    exports_filtered = exports[exports['partner'] != 'World']
    imports_filtered = imports[imports['partner'] != 'World']

    top_export_partners = exports_filtered.sort_values('value', ascending=False).head(10)
    top_import_partners = imports_filtered.sort_values('value', ascending=False).head(10)
    top_yoy = df_latest.sort_values('yoy_change', ascending=False).head(5)
    bottom_yoy = df_latest.sort_values('yoy_change', ascending=True).head(5)

    top_partners = (
        df[df['partner'] != 'World'].groupby('partner')['value'].sum()
        .sort_values(ascending=False)
        .head(5)
        .index.tolist()
    )

    df_top = df[df['partner'].isin(top_partners)]
    trend = df_top.pivot_table(
        index='date',
        columns=['partner', 'trade_type'],
        values='value'
    )

    pivot = df.pivot_table(
        index=['date', 'partner'],
        columns='trade_type',
        values='value',
        aggfunc='sum'
    ).fillna(0)

    pivot['trade_balance'] = (
        pivot.get('Total Exports', 0) - pivot.get('Total Imports', 0)
    )

    return {
        'latest_date': latest_date,
        'top_export_partners': top_export_partners,
        'top_import_partners': top_import_partners,
        'top_yoy': top_yoy,
        'bottom_yoy': bottom_yoy,
        'trend': trend,
        'trade_balance': pivot.reset_index()
    }

# Semiconductors
def load_wsts_billings_data(engine):
    query = """
    SELECT date, country, value, unit, sector, indicator, period_type
    FROM trade_wsts_billings_latest_processed
    WHERE period_type IN ('month', 'annual')
    ORDER BY date, country;
    """
    return pd.read_sql(query, engine)

def analyse_wsts_billings(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    
    # Filter for semiconductors only
    df = df[(df['sector'] == 'semiconductors') & (df['indicator'] == 'billings')]

    # Split by period type
    df_month = df[df['period_type'] == 'month']
    df_annual = df[df['period_type'] == 'annual']

    # Latest Monthly Snapshot
    latest_month = df_month['date'].max()
    latest_month_df = df_month[df_month['date'] == latest_month]
    # Filter out 'World' from top monthly regions
    latest_month_df_filtered = latest_month_df[latest_month_df['country'] != 'World']
    top_monthly_regions = latest_month_df_filtered.sort_values('value', ascending=False)

    # Monthly Time Series Trend
    trend_month = (
        df_month.groupby(['date', 'country'], as_index=False)
        .agg({'value': 'sum'})
        .sort_values(['country', 'date'])
    )
    trend_month_pivot = trend_month.pivot(index='date', columns='country', values='value')

    # Annual Time Series Trend
    trend_annual = (
        df_annual.groupby(['date', 'country'], as_index=False)
        .agg({'value': 'sum'})
        .sort_values(['country', 'date'])
    )
    trend_annual_pivot = trend_annual.pivot(index='date', columns='country', values='value')

    # Year-over-Year Change (Monthly)
    df_month = df_month.sort_values(['country', 'date'])
    df_month['yoy_change'] = (
        df_month.groupby('country')['value']
        .transform(lambda x: x.pct_change(periods=12) * 100)
    )

    # Annual Growth Rate
    df_annual = df_annual.sort_values(['country', 'date'])
    df_annual['yoy_change'] = (
        df_annual.groupby('country')['value']
        .transform(lambda x: x.pct_change(periods=1) * 100)
    )

    # Volatility (Standard Deviation)
    volatility = (
        df_month.groupby('country')['value']
        .std()
        .sort_values(ascending=False)
    )

    # Market Share (monthly, using World as denominator)
    monthly_world = df_month[df_month['country'] == 'World'][['date', 'value']].rename(columns={'value': 'world_total'})
    df_month = pd.merge(df_month, monthly_world, on='date', how='left')
    df_month['market_share'] = df_month['value'] / df_month['world_total']

    # Latest Annual Snapshot
    latest_annual = df_annual['date'].max()
    latest_annual_df = df_annual[df_annual['date'] == latest_annual]
    # Filter out 'World' from top annual regions
    latest_annual_df_filtered = latest_annual_df[latest_annual_df['country'] != 'World']
    top_annual_regions = latest_annual_df_filtered.sort_values('value', ascending=False)

    return {
        'latest_month': latest_month,
        'latest_annual': latest_annual,
        'top_monthly_regions': top_monthly_regions,
        'top_annual_regions': top_annual_regions,
        'trend_monthly': trend_month_pivot,
        'trend_annual': trend_annual_pivot,
        'yoy_monthly': df_month[['date', 'country', 'yoy_change']],
        'yoy_annual': df_annual[['date', 'country', 'yoy_change']],
        'volatility': volatility,
        'market_share_monthly': df_month[['date', 'country', 'market_share']]
    }


# Save EDA outputs
def save_trade_eda_outputs(output_dir, engine):
    os.makedirs(output_dir, exist_ok=True)

    # 1. Export/Import Trade Analysis
    print("üìä Analyzing export/import trade data...")
    export_df = load_korea_export_trade_data(engine)
    export_insights = analyse_trade(export_df, mode='export')
    
    import_df = load_korea_import_trade_data(engine)
    import_insights = analyse_trade(import_df, mode='import')
    
    # Save trade analysis results
    export_insights['top_partners'].to_csv(
        os.path.join(output_dir, "export_top_partners.csv"), index=False
    )
    import_insights['top_partners'].to_csv(
        os.path.join(output_dir, "import_top_partners.csv"), index=False
    )
    
    # 2. Export/Import Items Analysis
    print("üì¶ Analyzing trade items data...")
    df_export_items = load_korea_export_increase_items_data(engine)
    df_import_items = load_korea_import_increase_items_data(engine)
    
    result_export = analyse_increase_items(df_export_items, mode='export')
    result_import = analyse_increase_items(df_import_items, mode='import')
    
    # Save items analysis results
    result_export['top_amount'].to_csv(
        os.path.join(output_dir, "export_top_items_by_amount.csv"), index=False
    )
    result_export['top_yoy_growth'].to_csv(
        os.path.join(output_dir, "export_top_items_by_yoy.csv"), index=False
    )
    result_import['top_amount'].to_csv(
        os.path.join(output_dir, "import_top_items_by_amount.csv"), index=False
    )
    result_import['top_yoy_growth'].to_csv(
        os.path.join(output_dir, "import_top_items_by_yoy.csv"), index=False
    )
    
    # 3. Trade YoY Analysis
    print("üìà Analyzing trade YoY trends...")
    df_trade_yoy = load_korea_trade_data(engine)
    trade_yoy_insights = analyse_trade_yoy(df_trade_yoy)
    
    trade_yoy_insights['top_export_partners'].to_csv(
        os.path.join(output_dir, "trade_yoy_top_export_partners.csv"), index=False
    )
    trade_yoy_insights['top_import_partners'].to_csv(
        os.path.join(output_dir, "trade_yoy_top_import_partners.csv"), index=False
    )
    trade_yoy_insights['trade_balance'].to_csv(
        os.path.join(output_dir, "trade_balance.csv"), index=False
    )
    
    # 4. Export/Import Value Index Analysis
    print("üíπ Analyzing value indices...")
    df_value_index = load_korea_export_import_main_items_data(engine)
    value_index_insights = analyse_export_import_value_index(df_value_index)
    
    value_index_insights['top_yoy'].to_csv(
        os.path.join(output_dir, "value_index_top_yoy.csv"), index=False
    )
    value_index_insights['bottom_yoy'].to_csv(
        os.path.join(output_dir, "value_index_bottom_yoy.csv"), index=False
    )
    value_index_insights['volatility'].to_csv(
        os.path.join(output_dir, "value_index_volatility.csv")
    )
    
    # 5. Semiconductor Billings Analysis
    print("üîå Analyzing semiconductor billings...")
    df_wsts = load_wsts_billings_data(engine)
    wsts_insights = analyse_wsts_billings(df_wsts)
    
    wsts_insights['top_monthly_regions'].to_csv(
        os.path.join(output_dir, "wsts_top_monthly_regions.csv"), index=False
    )
    wsts_insights['top_annual_regions'].to_csv(
        os.path.join(output_dir, "wsts_top_annual_regions.csv"), index=False
    )
    wsts_insights['volatility'].to_csv(
        os.path.join(output_dir, "wsts_volatility.csv")
    )
    
    # Save trend and YoY data
    wsts_insights['trend_monthly'].to_csv(
        os.path.join(output_dir, "wsts_trend_monthly.csv")
    )
    wsts_insights['trend_annual'].to_csv(
        os.path.join(output_dir, "wsts_trend_annual.csv")
    )
    wsts_insights['yoy_monthly'].to_csv(
        os.path.join(output_dir, "wsts_yoy_monthly.csv"), index=False
    )
    wsts_insights['yoy_annual'].to_csv(
        os.path.join(output_dir, "wsts_yoy_annual.csv"), index=False
    )
    wsts_insights['market_share_monthly'].to_csv(
        os.path.join(output_dir, "wsts_market_share_monthly.csv"), index=False
    )
    
    # Fixed Key insights
    key_insights = {
        "analysis_timestamp": pd.Timestamp.now().isoformat(),
        "export_analysis": {
            "latest_date": str(result_export['latest_date']),
            "total_records": int(result_export['total_records']),
            "top_commodity": safe_get_value(result_export['top_amount'], 0, 'commodity_name_en'),
            "top_commodity_amount": safe_convert_numeric(
                safe_get_value(result_export['top_amount'], 0, 'export_amount')
            ),
                        "top_yoy_growth_commodity": safe_get_value(result_export['top_yoy_growth'], 0, 'commodity_name_en'),
            "top_yoy_growth_value": safe_convert_numeric(
                safe_get_value(result_export['top_yoy_growth'], 0, 'trade_yoy')
            )
        },
        "import_analysis": {
            "latest_date": str(result_import['latest_date']),
            "total_records": int(result_import['total_records']),
            "top_commodity": safe_get_value(result_import['top_amount'], 0, 'commodity_name_en'),
            "top_commodity_amount": safe_convert_numeric(
                safe_get_value(result_import['top_amount'], 0, 'import_amount')
            ),
            "top_yoy_growth_commodity": safe_get_value(result_import['top_yoy_growth'], 0, 'commodity_name_en'),
            "top_yoy_growth_value": safe_convert_numeric(
                safe_get_value(result_import['top_yoy_growth'], 0, 'trade_yoy')
            )
        },
        "trade_balance": {
            "latest_date": str(trade_yoy_insights['latest_date']),
            "top_export_partner": safe_get_value(trade_yoy_insights['top_export_partners'], 0, 'partner'),
            "top_import_partner": safe_get_value(trade_yoy_insights['top_import_partners'], 0, 'partner'),
            "export_top_value": safe_convert_numeric(
                safe_get_value(trade_yoy_insights['top_export_partners'], 0, 'value')
            ),
            "import_top_value": safe_convert_numeric(
                safe_get_value(trade_yoy_insights['top_import_partners'], 0, 'value')
            )
        },
        "value_index": {
            "top_yoy_item": safe_get_value(value_index_insights['top_yoy'], 0, 'item_en'),
            "top_yoy_value": safe_convert_numeric(
                safe_get_value(value_index_insights['top_yoy'], 0, 'yoy_change')
            ),
            "bottom_yoy_item": safe_get_value(value_index_insights['bottom_yoy'], 0, 'item_en'),
            "bottom_yoy_value": safe_convert_numeric(
                safe_get_value(value_index_insights['bottom_yoy'], 0, 'yoy_change')
            )
        },
        "semiconductors": {
            "latest_month": str(wsts_insights['latest_month']),
            "latest_annual": str(wsts_insights['latest_annual']),
            "top_monthly_country": safe_get_value(wsts_insights['top_monthly_regions'], 0, 'country'),
            "top_annual_country": safe_get_value(wsts_insights['top_annual_regions'], 0, 'country')
        }
    }

    # Save key insights as JSON
    with open(os.path.join(output_dir, "key_insights.json"), "w", encoding='utf-8') as f:
        json.dump(key_insights, f, ensure_ascii=False, indent=2)

    print("‚úÖ All outputs saved.")
    
    return {
        "export_insights": export_insights,
        "import_insights": import_insights,
        "export_items": result_export,
        "import_items": result_import,
        "trade_yoy": trade_yoy_insights,
        "value_index": value_index_insights,
        "semiconductor": wsts_insights,
        "key_insights": key_insights
    }


# Gemini Insight
def generate_gemini_insights(eda_results, output_dir):
    try:   
        # Check if eda_results is None or empty
        if not eda_results or not isinstance(eda_results, dict):
            print("‚ùå No EDA results available for Gemini insights generation")
            return None
            
        # Extract key data points with safe access
        export_data = {
            "latest_date": str(eda_results.get('export_items', {}).get('latest_date', 'N/A')),
            "total_records": eda_results.get('export_items', {}).get('total_records', 0),
            "top_commodity": "N/A",
            "top_yoy_growth": "N/A",
            "top_commodity_amount": 0
        }
        
        # Safely extract export data
        export_items = eda_results.get('export_items', {})
        if export_items and 'top_amount' in export_items and len(export_items['top_amount']) > 0:
            export_data["top_commodity"] = export_items['top_amount'].iloc[0].get('commodity_name_en', 'N/A')
            export_data["top_commodity_amount"] = float(export_items['top_amount'].iloc[0].get('export_amount', 0))
        
        if export_items and 'top_yoy_growth' in export_items and len(export_items['top_yoy_growth']) > 0:
            export_data["top_yoy_growth"] = float(export_items['top_yoy_growth'].iloc[0].get('trade_yoy', 0))
        
        import_data = {
            "latest_date": str(eda_results.get('import_items', {}).get('latest_date', 'N/A')),
            "total_records": eda_results.get('import_items', {}).get('total_records', 0),
            "top_commodity": "N/A",
            "top_yoy_growth": "N/A",
            "top_commodity_amount": 0
        }
        
        # Safely extract import data
        import_items = eda_results.get('import_items', {})
        if import_items and 'top_amount' in import_items and len(import_items['top_amount']) > 0:
            import_data["top_commodity"] = import_items['top_amount'].iloc[0].get('commodity_name_en', 'N/A')
            import_data["top_commodity_amount"] = float(import_items['top_amount'].iloc[0].get('import_amount', 0))
        
        if import_items and 'top_yoy_growth' in import_items and len(import_items['top_yoy_growth']) > 0:
            import_data["top_yoy_growth"] = float(import_items['top_yoy_growth'].iloc[0].get('trade_yoy', 0))
        
        semiconductor_data = {
            "latest_month": str(eda_results.get('semiconductor', {}).get('latest_month', 'N/A')),
            "top_region": "N/A",
            "top_region_value": 0
        }
        
        # Safely extract semiconductor data
        semiconductor = eda_results.get('semiconductor', {})
        if semiconductor and 'top_monthly_regions' in semiconductor and len(semiconductor['top_monthly_regions']) > 0:
            semiconductor_data["top_region"] = semiconductor['top_monthly_regions'].iloc[0].get('country', 'N/A')
            semiconductor_data["top_region_value"] = float(semiconductor['top_monthly_regions'].iloc[0].get('value', 0))
        
        trade_balance_data = {
            "latest_date": str(eda_results.get('trade_yoy', {}).get('latest_date', 'N/A')),
            "top_export_partner": "N/A",
            "top_import_partner": "N/A"
        }
        
        # Safely extract trade balance data
        trade_yoy = eda_results.get('trade_yoy', {})
        if trade_yoy and 'top_export_partners' in trade_yoy and len(trade_yoy['top_export_partners']) > 0:
            trade_balance_data["top_export_partner"] = trade_yoy['top_export_partners'].iloc[0].get('partner', 'N/A')
        
        if trade_yoy and 'top_import_partners' in trade_yoy and len(trade_yoy['top_import_partners']) > 0:
            trade_balance_data["top_import_partner"] = trade_yoy['top_import_partners'].iloc[0].get('partner', 'N/A')

        prompt = f"""
**Role**: You are a senior economic strategist analyzing cross-sector ripple effects. Extract non-obvious implications from the data below.

**Data Context**:
- Analysis Period: {export_data['latest_date']}
- Data Scope: Korea's export/import trade, semiconductor industry, and trade partnerships

**Key Data Points**:

1. **Export Performance**:
   - Top Export Commodity: {export_data['top_commodity']} (${export_data['top_commodity_amount']:,.0f})
   - Highest YoY Growth: {export_data['top_yoy_growth']:.1f}%
   - Total Records Analyzed: {export_data['total_records']}

2. **Import Trends**:
   - Top Import Commodity: {import_data['top_commodity']} (${import_data['top_commodity_amount']:,.0f})
   - Highest YoY Growth: {import_data['top_yoy_growth']:.1f}%
   - Total Records Analyzed: {import_data['total_records']}

3. **Semiconductor Industry**:
   - Latest Data: {semiconductor_data['latest_month']}
   - Top Region: {semiconductor_data['top_region']} (${semiconductor_data['top_region_value']:,.0f})

4. **Trade Partnerships**:
   - Top Export Partner: {trade_balance_data['top_export_partner']}
   - Top Import Partner: {trade_balance_data['top_import_partner']}


### **Required Output Format**
## Korea Trade Sector Second-Order Effect Analysis

### Top 1 actionable insights 
‚Ä¢ (e.g., "Semiconductor export surge ‚Üí expect supply chain optimization") (1 line)
### Key risks 
‚Ä¢ (e.g., "Trade dependency on key partners may impact export stability") (1 line)
### Recommended actions 
‚Ä¢ (e.g., "Diversify export markets and strengthen trade partnerships") (1 line)

### Core Trend
‚Ä¢ Korea Trade: [TREND SUMMARY IN 5‚Äì10 WORDS]  
‚Ä¢ **Direct Impact**: [IMMEDIATE OUTCOME IN 1 SENTENCE]

### Hidden Effects
1. **[EFFECT 1 NAME]**
   - *Catalyst*: [PRIMARY DRIVER]
   - *Transmission*: [HOW IT SPREADS THROUGH SYSTEM]
   - *Evidence*: [DATA POINT OR HISTORICAL PRECEDENT]

2. **[EFFECT 2 NAME]**
   - *Catalyst*: [PRIMARY DRIVER]
   - *Transmission*: [HOW IT SPREADS THROUGH SYSTEM]
   - *Evidence*: [DATA POINT OR HISTORICAL PRECEDENT]

### Strategic Recommendations
üõ† **Immediate Actions**: [CONCRETE STEPS]
üìä **Monitoring Metrics**: [KEY INDICATORS]
üéØ **Long-term Strategy**: [STRATEGIC DIRECTION]

### Risk Assessment
‚ö†Ô∏è **High Risk**: [CRITICAL CONCERN]
‚ö†Ô∏è **Medium Risk**: [MODERATE CONCERN]
‚ö†Ô∏è **Low Risk**: [MINOR CONCERN]

### Market Intelligence
üìà **Bullish Signals**: [POSITIVE INDICATORS]
üìâ **Bearish Signals**: [NEGATIVE INDICATORS]
üîÑ **Neutral Factors**: [BALANCED ELEMENTS]

**Analysis Guidelines**:
- Focus on actionable intelligence
- Consider global geopolitical dynamics
- Assess Korea's competitive positioning
- Identify emerging trends and risks
- Provide specific, measurable recommendations
"""

        response = MODEL.generate_content(prompt)
        gemini_insight = response.text.strip()

        # Save insights
        with open(os.path.join(output_dir, "gemini_insights_korea_trade.txt"), "w", encoding="utf-8") as f:
            f.write(gemini_insight)

        # JSON for programmatic access
        insight_data = {
            "generated_at": pd.Timestamp.now().isoformat(),
            "analysis_period": str(export_data['latest_date']),
            "key_metrics": {
                "export": export_data,
                "import": import_data,
                "semiconductor": semiconductor_data,
                "trade_balance": trade_balance_data
            },
            "insights": gemini_insight
        }
        
        with open(os.path.join(output_dir, "gemini_insights_data.json"), "w", encoding="utf-8") as f:
            json.dump(insight_data, f, indent=2, ensure_ascii=False)

        print("‚úÖ Gemini strategic insights generated and saved.")
        print(f"üìÑ Markdown: gemini_strategic_insights.md")
        print(f"üìä Data: gemini_insights_data.json")
        
        return insight_data

    except Exception as e:
        print(f"‚ùå Gemini insight generation failed: {e}")
        return None


if __name__ == "__main__":
    # Create output directory
    os.makedirs(eda_path, exist_ok=True)
    
    # Run complete analysis
    results = save_trade_eda_outputs(eda_path, engine)
    
    # Generate AI-powered insights
    generate_gemini_insights(results, eda_path)
    
    print(f"\n‚úÖ All data saved to: {eda_path}")
    print("="*50)