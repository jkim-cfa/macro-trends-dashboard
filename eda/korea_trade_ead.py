import os
import warnings
import pandas as pd
from sqlalchemy import create_engine
from dotenv import load_dotenv
import json
import google.generativeai as genai

# Configuration
warnings.filterwarnings('ignore')
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL_NAME = 'gemini-1.5-flash'
genai.configure(api_key=GEMINI_API_KEY)
MODEL = genai.GenerativeModel(GEMINI_MODEL_NAME)

EDA_DIR = os.getenv("EDA_DIR")
eda_path = os.path.join(EDA_DIR, "outputs", "korea_trade")

# DB connection
PG_USER = os.getenv("POSTGRES_USER")
PG_PASSWORD = os.getenv("POSTGRES_PASSWORD")
PG_DB = os.getenv("POSTGRES_DB")
PG_HOST = os.getenv("POSTGRES_HOST")
PG_PORT = os.getenv("POSTGRES_PORT")

engine = create_engine(f"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}")

# Korea Export Trade
def load_korea_export_trade_data(engine):
    query = """
    SELECT date, country, partner, indicator, export_amount, trade_yoy, trade_share
    FROM trade_korea_export_country_variation_processed
    ORDER BY date DESC, trade_share DESC, export_amount DESC;
    """
    return pd.read_sql(query, engine)

# Korea Import Trade
def load_korea_import_trade_data(engine):
    query = """
    SELECT date, country, partner, indicator, import_amount, trade_yoy, trade_share
    FROM trade_korea_import_country_variation_processed
    ORDER BY date DESC, trade_share DESC, import_amount DESC;
    """
    return pd.read_sql(query, engine)

# mode must be 'export' or 'import'
def analyse_trade(df, mode='export'):
    assert mode in ['export', 'import']
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')

    amount_col = 'export_amount' if mode == 'export' else 'import_amount'

    # Latest month
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]

    # Exclude World
    df_latest_filtered = df_latest[df_latest['partner'] != 'World']
    top_partners = (
        df_latest_filtered.groupby(['country', 'partner'], as_index=False)
        .agg({amount_col: 'sum', 'trade_share': 'sum'})
        .sort_values(amount_col, ascending=False)
        .head(5)
    )

    # Partner share trends (filter by significant trade share)
    avg_share_by_partner = df.groupby('partner')['trade_share'].mean()
    significant_partners = avg_share_by_partner[avg_share_by_partner >= 0.1].index
    df_significant = df[df['partner'].isin(significant_partners)]

    share_trends = (
        df_significant.groupby(['date', 'country', 'partner'], as_index=False)
        .agg({'trade_share': 'sum'})
        .sort_values(['country', 'partner', 'date'])
    )

    # Summary statistics
    summary_stats = df[[amount_col, 'trade_yoy']].describe().round(2)

    # Trend analysis for top 3
    top3 = top_partners.head(3)[['country', 'partner']]
    df_filtered = df[df['partner'] != 'World']
    mask = df_filtered.set_index(['country', 'partner']).index.isin(top3.set_index(['country', 'partner']).index)
    top3_trend = df_filtered[mask][['date', 'country', 'partner', amount_col, 'trade_share']].sort_values(['country', 'partner', 'date'])

    return {
        'mode': mode,
        'top_partners': top_partners,
        'share_trends': share_trends,
        'summary_stats': summary_stats,
        'top3_trend': top3_trend
    }

# Map English Commodity Names
translation_map = {
# Electronics
"ë©”ëª¨ë¦¬": "Memory chips",
"í”„ë¡œì„¸ì„œì™€ ì»¨íŠ¸ë¡¤ëŸ¬[ë©”ëª¨ë¦¬ã†ë³€í™˜ê¸°ã†ë…¼ë¦¬íšŒë¡œã†ì¦í­ê¸°ã†í´ë¡(clock)ã†íƒ€ì´ë°(timing) íšŒë¡œë‚˜ ê·¸ ë°–ì˜ íšŒë¡œë¥¼ ê°–ì¶˜ ê²ƒì¸ì§€ëŠ” ìƒê´€ì—†ë‹¤]": "Processors and controllers",
"ì†”ë¦¬ë“œ ìŠ¤í…Œì´íŠ¸(solid-state)ì˜ ë¹„íœ˜ë°œì„± ê¸°ì–µì¥ì¹˜": "SSD storage",
"ì¸ì‡„íšŒë¡œ": "Printed circuits",
"ë°˜ë„ì²´ë””ë°”ì´ìŠ¤ë‚˜ ì „ìì§‘ì íšŒë¡œ ì œì¡°ìš© ê¸°ê³„ì™€ ê¸°ê¸°": "Semiconductor manufacturing equipment",
"ìœ ê¸°ë°œê´‘ë‹¤ì´ì˜¤ë“œ(ì˜¤ì—˜ì´ë””)ì˜ ê²ƒ": "OLED displays",
# Vehicles
"ì‹¤ë¦°ë”ìš©ëŸ‰ì´ 1,500ì‹œì‹œ ì´ˆê³¼ 3,000ì‹œì‹œ ì´í•˜ì¸ ê²ƒ": "Vehicles (1.5-3L engine)",
"ê·¸ ë°–ì˜ ì°¨ëŸ‰(ë¶ˆê½ƒì í™”ì‹ í”¼ìŠ¤í†¤ ë‚´ì—°ê¸°ê´€ê³¼ ì¶”ì§„ìš© ëª¨í„°ë¡œì„œì˜ ì „ë™ê¸°ë¥¼ ë‘˜ ë‹¤ ê°–ì¶˜ ê²ƒìœ¼ë¡œì„œ, ì™¸ë¶€ ì „ì›ì— í”ŒëŸ¬ê·¸ë¥¼ ê½‚ì•„ ì¶©ì „í•  ìˆ˜ ìˆëŠ” ë°©ì‹ì˜ ê²ƒì€ ì œì™¸í•œë‹¤)": "Hybrid vehicles (non-plug-in)",
"ìŠ¹ìš©ìë™ì°¨ìš©[ìŠ¤í…Œì´ì…˜ì™œê±´(station wagon)ê³¼ ê²½ì£¼ ìë™ì°¨ìš©ì„ í¬í•¨í•œë‹¤]": "Passenger vehicles",
"ê¸°ì–´ë°•ìŠ¤ì™€ ê·¸ ë¶€ë¶„í’ˆ": "Transmission parts",
"ê·¸ ë°–ì˜ í™”ë¬¼ì„ ê³¼ í™”ê°ì„ ": "Other Cargo & Passenger Ships",
# Machinery
"ì œ8471í˜¸ì— í•´ë‹¹í•˜ëŠ” ê¸°ê³„ì˜ ë¶€ë¶„í’ˆê³¼ ë¶€ì†í’ˆ": "Machinery parts (HS8471)",
"360ë„ íšŒì „ì˜ ìƒë¶€êµ¬ì¡°ë¥¼ ê°€ì§„ ê¸°ê³„": "Rotating machinery",
"íŒŒì‡„ê¸°ë‚˜ ë¶„ì‡„ê¸°": "Crushers/grinders",
"ìì²´ ì¤‘ëŸ‰ì´ 2,000í‚¬ë¡œê·¸ë¨ì„ ì´ˆê³¼í•˜ëŠ” ê²ƒ": "Heavy equipment (>2T)",
"íƒ±ì»¤(tanker)": "Tankers",
# Chemicals
"íŒŒë¼-í¬ì‹¤ë Œ": "Para-xylene",
"ì˜¤ë¥´í† ì¸ì‚°ìˆ˜ì†Œ ì´ì•”ëª¨ëŠ„(ì¸ì‚°ì´ì•”ëª¨ëŠ„)": "Ammonium phosphate",
"í™©ì‚°ì•”ëª¨ëŠ„": "Ammonium sulfate",
"ì‚°í™”ë‹ˆì¼ˆê³¼ ìˆ˜ì‚°í™”ë‹ˆì¼ˆ": "Nickel compounds",
"ê²½ì§ˆìœ (è¼•è³ªæ²¹)ì™€ ì¡°ì œí’ˆ": "Light oils",
"ë°•í•˜ìœ [ë©˜íƒ€ í”¼í˜ë¦¬íƒ€(Mentha piperita)]": "Peppermint oil",
"ë©”í‹¸ë””ì—íƒ„ì˜¬ì•„ë¯¼ê³¼ ì—í‹¸ë””ì—íƒ„ì˜¬ì•„ë¯¼": "Methyldiethanolamine & Ethyldiethanolamine",
# Energy & Raw Materials
"ìœ ì—°íƒ„": "Bituminous coal",
"ì„ìœ ì™€ ì—­ì²­ìœ (ç€é‘æ²¹)(ì›ìœ ë¡œ í•œì •í•œë‹¤)": "Crude petroleum oil",
"êµ¬ë¦¬ê´‘ê³¼ ê·¸ ì •ê´‘(ç²¾é‘›)": "Copper ores and concentrates",
"ì‘ê²°ì‹œí‚¤ì§€ ì•Šì€ ê²ƒ": "Uncondensed materials",
"ìš°ë¼ëŠ„ 235ë¥¼ ë†ì¶•í•œ ìš°ë¼ëŠ„ê³¼ ê·¸ í™”í•©ë¬¼, í”Œë£¨í† ëŠ„ê³¼ ê·¸ í™”í•©ë¬¼, í•©ê¸ˆã†ë¶„ì‚°ë¬¼(åˆ†æ•£ç‰©)[ì„œë©§(cermet)ì„ í¬í•¨í•œë‹¤]ã†ë„ìì œí’ˆê³¼ ì´ë“¤ì˜ í˜¼í•©ë¬¼(ìš°ë¼ëŠ„ 235ë¥¼ ë†ì¶•í•œ ìš°ë¼ëŠ„ã†í”Œë£¨í† ëŠ„ì´ë‚˜ ì´ë“¤ì˜ í™”í•©ë¬¼ì„ í•¨ìœ í•˜ëŠ” ê²ƒìœ¼ë¡œ í•œì •í•œë‹¤)": "Enriched uranium and plutonium compounds",
"ì•„ë¯¸ë…¸ë ‰ìŠ¤(INN)ã†ë¸Œë¡œí‹°ì¡¸ëŒ(INN)ã†í´ë¡œí‹°ì•„ì œíŒœ(INN)ã†í´ë¡ì‚¬ì¡¸ëŒ(INN)ã†ë±ìŠ¤íŠ¸ë¡œëª¨ë¼ë§ˆì´ë“œ(INN)ã†í• ë¡ì‚¬ì¡¸ëŒ(INN)ã†ì¼€íƒ€ì¡¸ëŒ(INN)ã†ë©”ì†Œì¹´ë¸Œ(INN)ã†ì˜¥ì‚¬ì¡¸ëŒ(INN)ã†í˜ëª°ë¦°(INN)ã†íœë””ë©”íŠ¸ë¼ì§„(INN)ã†íœë©”íŠ¸ë¼ì§„(INN)ã†ì„œíœíƒ€ë‹(INN)ê³¼ ì´ë“¤ì˜ ì—¼": "Pharmaceutical compounds",
"íƒ„í™”ì¹¼ìŠ˜": "Calcium carbide",
"ì¡°ìœ (ç²—æ²¹)": "Crude petroleum oil",
# Other
"í¬ëœë² ë¦¬(cranberry)ã†ë¹Œë² ë¦¬(bilberry)ì™€ ê·¸ ë°–ì˜ ë°•ì‹œë‹ˆì—„(Vaccinium)ì†ì˜ ê³¼ì‹¤": "Cranberries and bilberries",
"ë¯¸ìƒë¬¼ì„± ì§€ë°©ê³¼ ê¸°ë¦„ ë° ì´ë“¤ì˜ ë¶„íšë¬¼": "Microbial fats and oils",
"ë¦¬íŠ¬ì´ì˜¨ ì¶•ì „ì§€": "Lithium batteries",
"ìŠ¤ë§ˆíŠ¸í°": "Smartphones",
"í…Œì´ë¸”ë¦°ë„¨(table linen)(ë©”ë¦¬ì•¼ìŠ¤ í¸ë¬¼ì´ë‚˜ ëœ¨ê°œì§ˆ í¸ë¬¼ë¡œ í•œì •í•œë‹¤)": "Table linen",
"ì£¼ë¡œ ì¬ìƒã†ë°˜(åŠ)í•©ì„± ìŠ¤í…Œì´í”Œì„¬ìœ ì™€ í˜¼ë°©í•œ ê²ƒ": "Recycled fiber blends",
"í…ŒíŠ¸ë¼ì‚¬ì´í´ë¦°ê³¼ ì´ë“¤ì˜ ìœ ë„ì²´, ì´ë“¤ì˜ ì—¼": "Tetracycline & Derivatives",
"ê³¡ë¬¼ì˜ ì”¨ëˆˆ[ì›ë˜ ëª¨ì–‘ì¸ ê²ƒã†ì••ì°©í•œ ê²ƒã†í”Œë ˆì´í¬(flake) ëª¨ì–‘ì¸ ê²ƒã†ì˜ê²Œ ë¶€ìˆœ ê²ƒìœ¼ë¡œ í•œì •í•œë‹¤]": "Cereal Germs",
"ì–´ë¥˜ì˜ ì§€ë°©ê³¼ ê¸°ë¦„ ë° ê·¸ ë¶„íšë¬¼[ê°„ìœ (è‚æ²¹)ëŠ” ì œì™¸í•œë‹¤]": "Fish Fats & Oils",
"ì œë„íŒì„ ê°–ì¶˜ ì œë„ê¸°(ìë™ì‹ì¸ì§€ì— ìƒê´€ì—†ë‹¤)": "Drawing Boards & Instruments",
"ê¸°íƒ€": "Others",
}

# Korea Increased Export Trade Items
def load_korea_export_increase_items_data(engine):
    query = """
    SELECT *
    FROM trade_korea_export_increase_items_processed
    WHERE commodity_name IS NOT NULL 
    AND export_amount > 0
    ORDER BY date DESC, export_amount DESC;
    """
    return pd.read_sql(query, engine)

# Korea Increased Import Trade Items
def load_korea_import_increase_items_data(engine):
    query = """
    SELECT *
    FROM trade_korea_import_increase_items_processed
    WHERE commodity_name IS NOT NULL 
    AND import_amount > 0
    ORDER BY date DESC, import_amount DESC;
    """
    return pd.read_sql(query, engine)

# Analyse Increase Export and Import Items
def analyse_increase_items(df, mode='export'):
    assert mode in ['export', 'import']

    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['trade_yoy'] = pd.to_numeric(df['trade_yoy'], errors='coerce')

    value_col = 'export_amount' if mode == 'export' else 'import_amount'
    df[value_col] = pd.to_numeric(df[value_col], errors='coerce')

    df['commodity_name_en'] = df['commodity_name'].map(translation_map)

    # Rename duplicate 'Others'
    count = 1
    for idx in df[df['commodity_name_en'] == 'Others'].index:
        df.loc[idx, 'commodity_name_en'] = f'Others Type: {count}'
        count += 1

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]

    print(f"[{mode.upper()}] Analysis for latest date: {latest_date}")
    print(f"Total records in latest month: {len(df_latest)}")

    # Top YoY growth commodities
    top_yoy_growth = (
        df_latest[df_latest['trade_yoy'].notna()]
        .groupby(['commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean',
        })
        .sort_values('trade_yoy', ascending=False)
        .head(10)
    )

    # Top by total amount
    top_amount = (
        df_latest.groupby(['commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean',
        })
        .sort_values(value_col, ascending=False)
        .head(10)
    )

    # Monthly trend
    top5 = top_amount['commodity_name_en'].head(5).tolist()
    monthly_trend = (
        df[df['commodity_name_en'].isin(top5)]
        .groupby(['date', 'commodity_name_en'], as_index=False)
        .agg({
            value_col: 'sum',
            'trade_yoy': 'mean'
        })
        .sort_values(['commodity_name_en', 'date'])
    )

    # YoY stats
    yoy_stats = df_latest[df_latest['trade_yoy'].notna()]['trade_yoy'].describe()

    # Partner analysis
    partner_analysis = (
        df_latest[df_latest['commodity_name_en'].isin(top5)]
        .groupby(['commodity_name_en', 'partner'], as_index=False)
        .agg({value_col: 'sum'})
        .sort_values(['commodity_name_en', value_col], ascending=[True, False])
    )

    return {
        'mode': mode,
        'latest_date': latest_date,
        'total_records': len(df_latest),
        'top_yoy_growth': top_yoy_growth,
        'top_amount': top_amount,
        'monthly_trend': monthly_trend,
        'yoy_statistics': yoy_stats,
        'partner_analysis': partner_analysis
    }

# Export and Import Main Items Value Analysis
def load_korea_export_import_main_items_data(engine):
    query = """
    SELECT date, country, category as trade_type, indicator as item, value, yoy_change
    FROM trade_korea_trade_items_yoy_processed
    ORDER BY date, trade_type, item;
    """
    return pd.read_sql(query, engine)

def analyse_export_import_value_index(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df['yoy_change'] = pd.to_numeric(df['yoy_change'], errors='coerce')

    # Translation
    translation_map = {
        "ì „ì§€": "Battery",
        "ë³€ì••ê¸°": "Transformer",
        "ì œíŠ¸ìœ ": "Jet fuel",
        "íœ˜ë°œìœ ": "Gasoline",
        "ê¸°ì´ˆë¬´ê¸°í™”í•©ë¬¼": "Basic chemical",
        "ì²œì—°ê°€ìŠ¤(LNG)": "Natural gas (LNG)",
        "ìœ¤í™œìœ ë°ê·¸ë¦¬ìŠ¤": "Lubricants and greases",
        "ì¤‘í›„íŒ(ë‘ê»˜3mmì´ìƒ)": "Thick plate (3mm or more)",
    }
    df['item_en'] = df['item'].map(translation_map).fillna(df['item'])

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date].dropna(subset=['yoy_change'])

    # Top â†‘ and Bottom â†“ YoY Changes
    top_yoy = df_latest.sort_values('yoy_change', ascending=False).head(5)
    bottom_yoy = df_latest.sort_values('yoy_change', ascending=True).head(5)

    # Volatility: standard deviation of value index
    volatility = (
        df.groupby(['item_en', 'trade_type'])['value']
        .std()
        .sort_values(ascending=False)
    )

    # Trend pivot tables (for external plotting)
    pivot_yoy = df.pivot_table(index='date', columns=['item_en', 'trade_type'], values='yoy_change')
    pivot_value = df.pivot_table(index='date', columns=['item_en', 'trade_type'], values='value')

    return {
        'latest_date': latest_date,
        'top_yoy': top_yoy,
        'bottom_yoy': bottom_yoy,
        'volatility': volatility,
        'pivot_yoy': pivot_yoy,
        'pivot_value': pivot_value,
    }

# Load Korea Trade Data
def load_korea_trade_data(engine):
    query = """
    SELECT date, country, partner, category AS trade_type, value, yoy_change
    FROM trade_korea_trade_yoy_processed
    ORDER BY date, trade_type, partner;
    """
    return pd.read_sql(query, engine)

# Analyze Trade YoY Data
def analyse_trade_yoy(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df['yoy_change'] = pd.to_numeric(df['yoy_change'], errors='coerce')

    # Latest snapshot
    latest_date = df['date'].max()
    df_latest = df[df['date'] == latest_date]
    exports = df_latest[df_latest['trade_type'] == 'Total Exports']
    imports = df_latest[df_latest['trade_type'] == 'Total Imports']

    top_export_partners = exports.sort_values('value', ascending=False).head(10)
    top_import_partners = imports.sort_values('value', ascending=False).head(10)
    top_yoy = df_latest.sort_values('yoy_change', ascending=False).head(5)
    bottom_yoy = df_latest.sort_values('yoy_change', ascending=True).head(5)

    top_partners = (
        df.groupby('partner')['value'].sum()
        .sort_values(ascending=False)
        .head(5)
        .index.tolist()
    )

    df_top = df[df['partner'].isin(top_partners)]
    trend = df_top.pivot_table(
        index='date',
        columns=['partner', 'trade_type'],
        values='value'
    )

    pivot = df.pivot_table(
        index=['date', 'partner'],
        columns='trade_type',
        values='value',
        aggfunc='sum'
    ).fillna(0)

    pivot['trade_balance'] = (
        pivot.get('Total Exports', 0) - pivot.get('Total Imports', 0)
    )

    return {
        'latest_date': latest_date,
        'top_export_partners': top_export_partners,
        'top_import_partners': top_import_partners,
        'top_yoy': top_yoy,
        'bottom_yoy': bottom_yoy,
        'trend': trend,
        'trade_balance': pivot.reset_index()
    }

# Semiconductors
def load_wsts_billings_data(engine):
    query = """
    SELECT date, country, value, unit, sector, indicator, period_type
    FROM trade_wsts_billings_latest_processed
    WHERE period_type IN ('month', 'annual')
    ORDER BY date, country;
    """
    return pd.read_sql(query, engine)

def analyse_wsts_billings(df):
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    
    # Filter for semiconductors only
    df = df[(df['sector'] == 'semiconductors') & (df['indicator'] == 'billings')]

    # Split by period type
    df_month = df[df['period_type'] == 'month']
    df_annual = df[df['period_type'] == 'annual']

    # Latest Monthly Snapshot
    latest_month = df_month['date'].max()
    latest_month_df = df_month[df_month['date'] == latest_month]
    top_monthly_regions = latest_month_df.sort_values('value', ascending=False)

    # Monthly Time Series Trend
    trend_month = (
        df_month.groupby(['date', 'country'], as_index=False)
        .agg({'value': 'sum'})
        .sort_values(['country', 'date'])
    )
    trend_month_pivot = trend_month.pivot(index='date', columns='country', values='value')

    # Annual Time Series Trend
    trend_annual = (
        df_annual.groupby(['date', 'country'], as_index=False)
        .agg({'value': 'sum'})
        .sort_values(['country', 'date'])
    )
    trend_annual_pivot = trend_annual.pivot(index='date', columns='country', values='value')

    # Year-over-Year Change (Monthly)
    df_month = df_month.sort_values(['country', 'date'])
    df_month['yoy_change'] = (
        df_month.groupby('country')['value']
        .transform(lambda x: x.pct_change(periods=12) * 100)
    )

    # Annual Growth Rate
    df_annual = df_annual.sort_values(['country', 'date'])
    df_annual['yoy_change'] = (
        df_annual.groupby('country')['value']
        .transform(lambda x: x.pct_change(periods=1) * 100)
    )

    # Volatility (Standard Deviation)
    volatility = (
        df_month.groupby('country')['value']
        .std()
        .sort_values(ascending=False)
    )

    # Market Share (monthly, using World as denominator)
    monthly_world = df_month[df_month['country'] == 'World'][['date', 'value']].rename(columns={'value': 'world_total'})
    df_month = pd.merge(df_month, monthly_world, on='date', how='left')
    df_month['market_share'] = df_month['value'] / df_month['world_total']

    # Latest Annual Snapshot
    latest_annual = df_annual['date'].max()
    latest_annual_df = df_annual[df_annual['date'] == latest_annual]
    top_annual_regions = latest_annual_df.sort_values('value', ascending=False)

    return {
        'latest_month': latest_month,
        'latest_annual': latest_annual,
        'top_monthly_regions': top_monthly_regions,
        'top_annual_regions': top_annual_regions,
        'trend_monthly': trend_month_pivot,
        'trend_annual': trend_annual_pivot,
        'yoy_monthly': df_month[['date', 'country', 'yoy_change']],
        'yoy_annual': df_annual[['date', 'country', 'yoy_change']],
        'volatility': volatility,
        'market_share_monthly': df_month[['date', 'country', 'market_share']]
    }


# Save EDA outputs
def save_trade_eda_outputs(output_dir, engine):
    os.makedirs(output_dir, exist_ok=True)

    # 1. Export/Import Trade Analysis
    print("ğŸ“Š Analyzing export/import trade data...")
    export_df = load_korea_export_trade_data(engine)
    export_insights = analyse_trade(export_df, mode='export')
    
    import_df = load_korea_import_trade_data(engine)
    import_insights = analyse_trade(import_df, mode='import')
    
    # Save trade analysis results
    export_insights['top_partners'].to_csv(
        os.path.join(output_dir, "export_top_partners.csv"), index=False
    )
    import_insights['top_partners'].to_csv(
        os.path.join(output_dir, "import_top_partners.csv"), index=False
    )
    
    # 2. Export/Import Items Analysis
    print("ğŸ“¦ Analyzing trade items data...")
    df_export_items = load_korea_export_increase_items_data(engine)
    df_import_items = load_korea_import_increase_items_data(engine)
    
    result_export = analyse_increase_items(df_export_items, mode='export')
    result_import = analyse_increase_items(df_import_items, mode='import')
    
    # Save items analysis results
    result_export['top_amount'].to_csv(
        os.path.join(output_dir, "export_top_items_by_amount.csv"), index=False
    )
    result_export['top_yoy_growth'].to_csv(
        os.path.join(output_dir, "export_top_items_by_yoy.csv"), index=False
    )
    result_import['top_amount'].to_csv(
        os.path.join(output_dir, "import_top_items_by_amount.csv"), index=False
    )
    result_import['top_yoy_growth'].to_csv(
        os.path.join(output_dir, "import_top_items_by_yoy.csv"), index=False
    )
    
    # 3. Trade YoY Analysis
    print("ğŸ“ˆ Analyzing trade YoY trends...")
    df_trade_yoy = load_korea_trade_data(engine)
    trade_yoy_insights = analyse_trade_yoy(df_trade_yoy)
    
    trade_yoy_insights['top_export_partners'].to_csv(
        os.path.join(output_dir, "trade_yoy_top_export_partners.csv"), index=False
    )
    trade_yoy_insights['top_import_partners'].to_csv(
        os.path.join(output_dir, "trade_yoy_top_import_partners.csv"), index=False
    )
    trade_yoy_insights['trade_balance'].to_csv(
        os.path.join(output_dir, "trade_balance.csv"), index=False
    )
    
    # 4. Export/Import Value Index Analysis
    print("ğŸ’¹ Analyzing value indices...")
    df_value_index = load_korea_export_import_main_items_data(engine)
    value_index_insights = analyse_export_import_value_index(df_value_index)
    
    value_index_insights['top_yoy'].to_csv(
        os.path.join(output_dir, "value_index_top_yoy.csv"), index=False
    )
    value_index_insights['bottom_yoy'].to_csv(
        os.path.join(output_dir, "value_index_bottom_yoy.csv"), index=False
    )
    value_index_insights['volatility'].to_csv(
        os.path.join(output_dir, "value_index_volatility.csv")
    )
    
    # 5. Semiconductor Billings Analysis
    print("ğŸ”Œ Analyzing semiconductor billings...")
    df_wsts = load_wsts_billings_data(engine)
    wsts_insights = analyse_wsts_billings(df_wsts)
    
    wsts_insights['top_monthly_regions'].to_csv(
        os.path.join(output_dir, "wsts_top_monthly_regions.csv"), index=False
    )
    wsts_insights['top_annual_regions'].to_csv(
        os.path.join(output_dir, "wsts_top_annual_regions.csv"), index=False
    )
    wsts_insights['volatility'].to_csv(
        os.path.join(output_dir, "wsts_volatility.csv")
    )
    
    # Save trend and YoY data
    wsts_insights['trend_monthly'].to_csv(
        os.path.join(output_dir, "wsts_trend_monthly.csv")
    )
    wsts_insights['trend_annual'].to_csv(
        os.path.join(output_dir, "wsts_trend_annual.csv")
    )
    wsts_insights['yoy_monthly'].to_csv(
        os.path.join(output_dir, "wsts_yoy_monthly.csv"), index=False
    )
    wsts_insights['yoy_annual'].to_csv(
        os.path.join(output_dir, "wsts_yoy_annual.csv"), index=False
    )
    wsts_insights['market_share_monthly'].to_csv(
        os.path.join(output_dir, "wsts_market_share_monthly.csv"), index=False
    )
    
     # Key insights
    key_insights = {
        "analysis_timestamp": pd.Timestamp.now().isoformat(),
        "export_analysis": {
            "latest_date": str(result_export['latest_date']),
            "total_records": result_export['total_records'],
            "top_commodity": result_export['top_amount'].iloc[0]['commodity_name_en'] if len(result_export['top_amount']) > 0 else "N/A",
            "top_yoy_growth": float(result_export['top_yoy_growth'].iloc[0]['trade_yoy']) if len(result_export['top_yoy_growth']) > 0 else "N/A"
        },
        "import_analysis": {
            "latest_date": str(result_import['latest_date']),
            "total_records": result_import['total_records'],
            "top_commodity": result_import['top_amount'].iloc[0]['commodity_name_en'] if len(result_import['top_amount']) > 0 else "N/A",
            "top_yoy_growth": float(result_import['top_yoy_growth'].iloc[0]['trade_yoy']) if len(result_import['top_yoy_growth']) > 0 else "N/A"
        },
        "trade_yoy_analysis": {
            "latest_date": str(trade_yoy_insights['latest_date']),
            "top_export_partner": trade_yoy_insights['top_export_partners'].iloc[0]['partner'] if len(trade_yoy_insights['top_export_partners']) > 0 else "N/A",
            "top_import_partner": trade_yoy_insights['top_import_partners'].iloc[0]['partner'] if len(trade_yoy_insights['top_import_partners']) > 0 else "N/A"
        },
        "semiconductor_analysis": {
            "latest_month": str(wsts_insights['latest_month']),
            "latest_annual": str(wsts_insights['latest_annual']),
            "top_monthly_region": wsts_insights['top_monthly_regions'].iloc[0]['country'] if len(wsts_insights['top_monthly_regions']) > 0 else "N/A"
        }
    }
    
    with open(os.path.join(output_dir, "key_insights.json"), "w", encoding='utf-8') as f:
        json.dump(key_insights, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… All EDA outputs saved to: {output_dir}")
    print(f"ğŸ“ Generated {len(os.listdir(output_dir))} files")
    
    return {
        "export_insights": export_insights,
        "import_insights": import_insights,
        "export_items": result_export,
        "import_items": result_import,
        "trade_yoy": trade_yoy_insights,
        "value_index": value_index_insights,
        "semiconductor": wsts_insights,
        "key_insights": key_insights
    }

# Gemini Insight
def generate_gemini_insights(eda_results, output_dir):
    try:   
        # Extract key data points
        export_data = {
            "latest_date": str(eda_results['export_items']['latest_date']),
            "total_records": eda_results['export_items']['total_records'],
            "top_commodity": eda_results['export_items']['top_amount'].iloc[0]['commodity_name_en'] if len(eda_results['export_items']['top_amount']) > 0 else "N/A",
            "top_yoy_growth": float(eda_results['export_items']['top_yoy_growth'].iloc[0]['trade_yoy']) if len(eda_results['export_items']['top_yoy_growth']) > 0 else "N/A",
            "top_commodity_amount": float(eda_results['export_items']['top_amount'].iloc[0]['export_amount']) if len(eda_results['export_items']['top_amount']) > 0 else 0
        }
        
        import_data = {
            "latest_date": str(eda_results['import_items']['latest_date']),
            "total_records": eda_results['import_items']['total_records'],
            "top_commodity": eda_results['import_items']['top_amount'].iloc[0]['commodity_name_en'] if len(eda_results['import_items']['top_amount']) > 0 else "N/A",
            "top_yoy_growth": float(eda_results['import_items']['top_yoy_growth'].iloc[0]['trade_yoy']) if len(eda_results['import_items']['top_yoy_growth']) > 0 else "N/A",
            "top_commodity_amount": float(eda_results['import_items']['top_amount'].iloc[0]['import_amount']) if len(eda_results['import_items']['top_amount']) > 0 else 0
        }
        
        semiconductor_data = {
            "latest_month": str(eda_results['semiconductor']['latest_month']),
            "top_region": eda_results['semiconductor']['top_monthly_regions'].iloc[0]['country'] if len(eda_results['semiconductor']['top_monthly_regions']) > 0 else "N/A",
            "top_region_value": float(eda_results['semiconductor']['top_monthly_regions'].iloc[0]['value']) if len(eda_results['semiconductor']['top_monthly_regions']) > 0 else 0
        }
        
        trade_balance_data = {
            "latest_date": str(eda_results['trade_yoy']['latest_date']),
            "top_export_partner": eda_results['trade_yoy']['top_export_partners'].iloc[0]['partner'] if len(eda_results['trade_yoy']['top_export_partners']) > 0 else "N/A",
            "top_import_partner": eda_results['trade_yoy']['top_import_partners'].iloc[0]['partner'] if len(eda_results['trade_yoy']['top_import_partners']) > 0 else "N/A"
        }

        prompt = f"""
**Role**: You are a senior economic strategist analyzing cross-sector ripple effects. Extract non-obvious implications from the data below.

**Data Context**:
- Analysis Period: {export_data['latest_date']}
- Data Scope: Korea's export/import trade, semiconductor industry, and trade partnerships

**Key Data Points**:

1. **Export Performance**:
   - Top Export Commodity: {export_data['top_commodity']} (${export_data['top_commodity_amount']:,.0f})
   - Highest YoY Growth: {export_data['top_yoy_growth']:.1f}%
   - Total Records Analyzed: {export_data['total_records']}

2. **Import Trends**:
   - Top Import Commodity: {import_data['top_commodity']} (${import_data['top_commodity_amount']:,.0f})
   - Highest YoY Growth: {import_data['top_yoy_growth']:.1f}%
   - Total Records Analyzed: {import_data['total_records']}

3. **Semiconductor Industry**:
   - Latest Data: {semiconductor_data['latest_month']}
   - Top Region: {semiconductor_data['top_region']} (${semiconductor_data['top_region_value']:,.0f})

4. **Trade Partnerships**:
   - Top Export Partner: {trade_balance_data['top_export_partner']}
   - Top Import Partner: {trade_balance_data['top_import_partner']}


### **Required Output Format**
## Korea Trade Sector Second-Order Effect Analysis

### Core Trend
â€¢ Korea Trade: [TREND SUMMARY IN 5â€“10 WORDS]  
â€¢ **Direct Impact**: [IMMEDIATE OUTCOME IN 1 SENTENCE]

### Hidden Effects
1. **[EFFECT 1 NAME]**
   - *Catalyst*: [PRIMARY DRIVER]
   - *Transmission*: [HOW IT SPREADS THROUGH SYSTEM]
   - *Evidence*: [DATA POINT OR HISTORICAL PRECEDENT]

2. **[EFFECT 2 NAME]**
   - *Catalyst*: [PRIMARY DRIVER]
   - *Transmission*: [HOW IT SPREADS THROUGH SYSTEM]
   - *Evidence*: [DATA POINT OR HISTORICAL PRECEDENT]

### Strategic Recommendations
ğŸ›  **Immediate Actions**: [CONCRETE STEPS]
ğŸ“Š **Monitoring Metrics**: [KEY INDICATORS]
ğŸ¯ **Long-term Strategy**: [STRATEGIC DIRECTION]

### Risk Assessment
âš ï¸ **High Risk**: [CRITICAL CONCERN]
âš ï¸ **Medium Risk**: [MODERATE CONCERN]
âš ï¸ **Low Risk**: [MINOR CONCERN]

### Market Intelligence
ğŸ“ˆ **Bullish Signals**: [POSITIVE INDICATORS]
ğŸ“‰ **Bearish Signals**: [NEGATIVE INDICATORS]
ğŸ”„ **Neutral Factors**: [BALANCED ELEMENTS]

**Analysis Guidelines**:
- Focus on actionable intelligence
- Consider global geopolitical dynamics
- Assess Korea's competitive positioning
- Identify emerging trends and risks
- Provide specific, measurable recommendations
"""

        response = MODEL.generate_content(prompt)
        gemini_insight = response.text.strip()

        # Save insights
        with open(os.path.join(output_dir, "gemini_insights_korea_trade.txt"), "w", encoding="utf-8") as f:
            f.write(gemini_insight)

        # JSON for programmatic access
        insight_data = {
            "generated_at": pd.Timestamp.now().isoformat(),
            "analysis_period": str(export_data['latest_date']),
            "key_metrics": {
                "export": export_data,
                "import": import_data,
                "semiconductor": semiconductor_data,
                "trade_balance": trade_balance_data
            },
            "insights": gemini_insight
        }
        
        with open(os.path.join(output_dir, "gemini_insights_data.json"), "w", encoding="utf-8") as f:
            json.dump(insight_data, f, indent=2, ensure_ascii=False)

        print("âœ… Gemini strategic insights generated and saved.")
        print(f"ğŸ“„ Markdown: gemini_strategic_insights.md")
        print(f"ğŸ“Š Data: gemini_insights_data.json")
        
        return insight_data

    except Exception as e:
        print(f"âŒ Gemini insight generation failed: {e}")
        return None


if __name__ == "__main__":
    # Run comprehensive EDA analysis and save all outputs
    print("ğŸš€ Starting Korea Trade EDA Analysis...")
    
    # Create output directory
    os.makedirs(eda_path, exist_ok=True)
    
    # Run complete analysis
    results = save_trade_eda_outputs(eda_path, engine)
    
    print("\n" + "="*50)
    print("ğŸ“Š ANALYSIS COMPLETE!")
    print("="*50)
    
    # Display key insights
    print(f"\nğŸ“ˆ Export Analysis:")
    print(f"   â€¢ Latest Date: {results['export_items']['latest_date']}")
    print(f"   â€¢ Total Records: {results['export_items']['total_records']}")
    print(f"   â€¢ Top Commodity: {results['export_items']['top_amount'].iloc[0]['commodity_name_en'] if len(results['export_items']['top_amount']) > 0 else 'N/A'}")
    
    print(f"\nğŸ“‰ Import Analysis:")
    print(f"   â€¢ Latest Date: {results['import_items']['latest_date']}")
    print(f"   â€¢ Total Records: {results['import_items']['total_records']}")
    print(f"   â€¢ Top Commodity: {results['import_items']['top_amount'].iloc[0]['commodity_name_en'] if len(results['import_items']['top_amount']) > 0 else 'N/A'}")
    
    print(f"\nğŸ”Œ Semiconductor Analysis:")
    print(f"   â€¢ Latest Month: {results['semiconductor']['latest_month']}")
    print(f"   â€¢ Top Region: {results['semiconductor']['top_monthly_regions'].iloc[0]['country'] if len(results['semiconductor']['top_monthly_regions']) > 0 else 'N/A'}")
    
    # Generate AI-powered insights
    print(f"\nğŸ¤– Generating AI-powered strategic insights...")
    gemini_results = generate_gemini_insights(results, eda_path)
    
    if gemini_results:
        print(f"\nğŸ“„ Strategic insights saved:")
        print(f"   â€¢ Markdown: gemini_insights_korea_trade.txt")
        print(f"   â€¢ Data: gemini_insights_data.json")
    
    print(f"\nğŸ“ All outputs saved to: {eda_path}")
    print("="*50)